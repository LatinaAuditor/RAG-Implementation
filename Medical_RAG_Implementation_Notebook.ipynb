{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by9EvAnkSpZf"
      },
      "source": [
        "### Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnwETBOE6Bz5"
      },
      "source": [
        "## Installing and Importing Necessary Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4GgLhZhUM4V"
      },
      "outputs": [],
      "source": [
        "# Installation for GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VOckDVkWGei"
      },
      "outputs": [],
      "source": [
        "# For installing the libraries & downloading models from HF Hub\n",
        "!pip install huggingface_hub==0.25.0 pandas==2.2.2 tiktoken==0.6.0 pymupdf==1.25.1 langchain==0.3.0 langchain-community==0.3.0 langchain-text-splitters==0.3.6 chromadb==0.5.5 sentence-transformers==3.2.0 numpy==1.26.0 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTY9GN4oWK3g"
      },
      "outputs": [],
      "source": [
        "#Libraries for processing dataframes,text\n",
        "import json,os\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "\n",
        "#Libraries for Loading Data, Chunking, Embedding, and Vector Databases\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "#Libraries for downloading and loading the llm\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtZWqj0wFTS1"
      },
      "source": [
        "## Question Answering using LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq1lhM4WFTS2"
      },
      "source": [
        "#### Downloading and Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\" # I used the Mistral 7b Model. This names the model\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\" #This names the base model."
      ],
      "metadata": {
        "id": "dA3XQMWmQLJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        ")# This code is storing the model in model path so I can load the model later."
      ],
      "metadata": {
        "id": "k4xQopMhvQ6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uncomment the below snippet of code if the runtime is connected to GPU.\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=5000,\n",
        "    n_gpu_layers=38,\n",
        "    n_batch=512\n",
        ") # This code downloads the mistral model and defines context window, batch window, and offloading GPU layers."
      ],
      "metadata": {
        "id": "2EvrdRKGvVAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzzkvIXvFTS4"
      },
      "source": [
        "#### Response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def response(query,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    model_output = llm(\n",
        "      prompt=query,\n",
        "      max_tokens=max_tokens,\n",
        "      temperature=temperature,\n",
        "      top_p=top_p,\n",
        "      top_k=top_k\n",
        "    )\n",
        "\n",
        "    return model_output['choices'][0]['text']"
      ],
      "metadata": {
        "id": "hG_IaZj0QLw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8YgK91SFjVY"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "model_response = response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "-JLIVmpPQH0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Query** 1: The query was cut off due to the size of the token. As it is limited to 128 tokens, it only provided one step of the protocol. It does provide informatio on what sepsis is.\n"
      ],
      "metadata": {
        "id": "kn53kqXzPXR0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6yxICeVFjVc"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input1 =\"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
        "model_response1 = response(user_input1)\n",
        "print(model_response1)"
      ],
      "metadata": {
        "id": "BdiHRgEqQIP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 2:** Similar to the first query, it was cut off because the size of tokens so it does not answer the question. It does a good job to of defining an abdominal pain."
      ],
      "metadata": {
        "id": "Ks93iQ_gRxiP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oflaoOGiFjVd"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "model_response= response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "N-mx9yboQIt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 3:** The response ignores the first part of the question as the query was not seperated out. Instead, it answers the second part of the question which is the cause."
      ],
      "metadata": {
        "id": "2DO9S6RkVOSy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUUqY4FbFjVe"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "model_response= response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "TEsVMaKaQJzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 4**:The response is not complete because of the tokens. It does provide two pieces of information related to emergency car and medications, but it also gives an explanation of TBI which was not asked."
      ],
      "metadata": {
        "id": "5l9dZt1Bb3Dn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5laPFTHrFjVf"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "model_response= response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "VfrlmrP5QKJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 5:** The response doesn't complete due to token size. It does answer the question until it stops."
      ],
      "metadata": {
        "id": "JVa67IbYPbas"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5myZ5dOOefc"
      },
      "source": [
        "## Question Answering using LLM with Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def response_2(query,max_tokens=1024,temperature=0,top_p=0.95,top_k=50): #increased the tokens due to limited responses in the previous queries.\n",
        "\n",
        "# A system message was provided to define beter the expected response and information..\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>>\n",
        "\n",
        "\n",
        "    You are an AI assistant designed to support a licensed medical professional. Your core functions are to assist with synthesizing information based on available records\n",
        "    and prompts asked by the users. Your persona is that of a helpful, accurate, and ethical tool. You are not a human clinician.\n",
        "\n",
        "    **Primary Directives:**\n",
        "    1.  **Safety First:** You must not provide medical advice, diagnoses, or medication recommendations. When generating text, strictly adhere to the information provided by the human user.\n",
        "    2.  **Source Reliability:** Use only peer-reviewed medical sources or explicitly provided patient data for generating responses.\n",
        "    3.  **No Hallucinations:** You must prevent the generation of inaccurate or unsupported information. If information is ambiguous, state this and ask for clarification.\n",
        "    4.  **Bias Mitigation:** Be mindful of and explicitly exclude non-clinically relevant demographic descriptors to avoid introducing bias.\n",
        "\n",
        " <</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "\n",
        "    model_output = llm(\n",
        "      prompt=query,\n",
        "      max_tokens=max_tokens,\n",
        "      temperature=temperature,\n",
        "      top_p=top_p,\n",
        "      top_k=top_k\n",
        "    )\n",
        "\n",
        "    return model_output['choices'][0]['text']"
      ],
      "metadata": {
        "id": "o9TGaGrHPe--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jg3r_LWOeff"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Provide details on the protocols needed for managing sepsis in a critical care unit. The output should be in an instructional format with bullets. Each bullet should be followed with a verb describing the key action.\" ##The prompt was updated to provide clear information and in a format that was easier to read\n",
        "model_response = response_2(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "YqM4VMw5ROhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qeuery 1:** The prompt was updated from being asked as a question to asking the model to provide a response to treating Sepsis in a specific format. With this information, it was able to give more detailed instructions and clear steps on the protocals for treating sepsis."
      ],
      "metadata": {
        "id": "cAyUm3mrjBK0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpyw4HjOeff"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "\n",
        "Provide the common symptons for appendicitis.\n",
        "\n",
        "Stop providing the common symptoms for appendicitis.\n",
        "\n",
        "Provide if appendicitis can be cured by medication or whether if surgery will be needed. If surgery is needed, describe which surgical procedures should be followed to treat appendicitis.\n",
        "''' ##The query was updated to seperate the two questions and give clearer instructions on the ask.\n",
        "model_response = response_2(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "GXl09pFfRPBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 2**: By seperating the query, I was able to get two responses from the query. It answered the symptoms and how it can be cured."
      ],
      "metadata": {
        "id": "LRL36bqLkb7a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRp92JQZOeff"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "\n",
        "Explain the top 5 possible causes for men and women developing patch hair loss, also known as bald spots. Denote which causes are for women, men, or both.\n",
        "Stop explaining the possible causes for men and women.\n",
        "\n",
        "\n",
        "Provide effective treatments and solutions to address sudden patch hair loss, also known as bald spots in women and men. If they are different, provide which treatment is more effective for women or men.\n",
        "'''\n",
        "model_response = response_2(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "JOgATEpMRPve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 3**: The prompt was rewritten to ask for more specific details by enumerating the number of causes and the number of treatments. This seemed to work as it was better at providing more details on both."
      ],
      "metadata": {
        "id": "qsS2xsAU_Qno"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA45zwyUOefg"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "\n",
        "Below I have described a recommended treamtment for someone who has sustained a muscle injury:\n",
        "\n",
        "\n",
        "Initial treatment for a muscle injury, such as a strain, often follows the RICE or PRICE method, focusing on pain and swelling control. This involves:\n",
        "- **Rest**: Avoiding activities that worsen pain or discomfort. It's generally recommended to avoid complete inactivity for too long, and gentle movement may be introduced as pain allows.\n",
        "- **Ice**: Applying cold packs to the injured area to help reduce swelling and pain. It is important to avoid applying ice directly to the skin and to use it for limited durations.\n",
        "- **Compression**: Using a bandage to wrap the injured area can help limit swelling. Care should be taken to ensure the bandage is not too tight, which could restrict circulation.\n",
        "- **Elevation**: Keeping the injured body part raised above heart level can assist with reducing swelling.\n",
        "- **Pain Management**:Managing pain can also involve over-the-counter options, but it is important to understand which ones are appropriate and when to use them, as some may interfere with healing in the very early stages of injury\n",
        "\n",
        "\n",
        "Use the above description to generate what treatments can be used a physical injury to brain tissue that might result in temporary or permanent impairment of brain function. ''' #asking to have output in a certain way\n",
        "model_response = response_2(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "VA7G8FOnRQZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 4**: In this query, I engineered it so I could provide it an example of the information I was looking for. This allowed the response to provide details on the treatment to support brain injury. It did add seaking professional medical assistance, which meets the system message prompt."
      ],
      "metadata": {
        "id": "AmgAgf7IOQeX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXxiSuBOefg"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = ''' What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?  Ask me an relevant questions before answering''' #asking clarification\n",
        "model_response = response_2(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "mE2GMQk8RQ_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = ''' What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\n",
        "\n",
        "Below are some important circumstances and information to consider in the response:\n",
        "1. The leg was factured below the knee.\n",
        "2. There was swelling and bruising at the time of the injury.\n",
        "3. There was no bleeding or open wound on the leg after the injury occurred.\n",
        "4. The person was not able to bear weight on the leg after the injury occurred.\n",
        "5. The injured person has a vitamin D deficiency but does not have any other underlying medical conditions.\n",
        "6. There are two people that can provide assistance and support during the initial care and transport.\n",
        "7. The only resources is car. The car is about a mile away.\n",
        "\n",
        "Provide the response in a bullet format, listing precautions first and then treatment steps. '''\n",
        "\n",
        "\n",
        "model_response = response_2(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "utaiFKinnPs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 5**: In this query, I asked AI to ask what questions it would need to provide a good response, based on the initial question. From those questions, I made up the data to answer and it provided me a comprehensive treatment list."
      ],
      "metadata": {
        "id": "74C8oxDLQIjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for RAG"
      ],
      "metadata": {
        "id": "t_O1PGdNO2M9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTpWESc53dL9"
      },
      "source": [
        "### Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#mounting google drive"
      ],
      "metadata": {
        "id": "ybj2cEnzRSXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_pdf = '/content/drive/MyDrive/medical_diagnosis_manual.pdf' #making the PDF data accessible"
      ],
      "metadata": {
        "id": "eH-LShlRiQJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_loader = PyMuPDFLoader(md_pdf) #loading the data"
      ],
      "metadata": {
        "id": "t4aBpcxYiyC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md = pdf_loader.load() #renaming the data"
      ],
      "metadata": {
        "id": "d-GXHzvWi3YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffj0ca3eZT4u"
      },
      "source": [
        "### Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9weTDzMxRRS"
      },
      "source": [
        "#### Checking the first 5 pages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(f\"Page Number : {i+1}\",end=\"\\n\")\n",
        "    print(md[i].page_content,end=\"\\n\") #This for loop checks the first five pages of the PDF."
      ],
      "metadata": {
        "id": "MSEiL--bRTZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first five pages are just table of contents."
      ],
      "metadata": {
        "id": "15IJ7r3sRLm8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wNNalNxPKT"
      },
      "source": [
        "#### Checking the number of pages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(md) #This checks the number of pages"
      ],
      "metadata": {
        "id": "-NuC-6SNRT7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 4,114 pages in the book."
      ],
      "metadata": {
        "id": "t5Ys1F_bRP_a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECMxTH-zB-R"
      },
      "source": [
        "### Data Chunking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name='cl100k_base',\n",
        "    chunk_size=512,\n",
        "    chunk_overlap= 40\n",
        ") #This is breaking down the medical book into various chunks. The chunks are seperated at 512 tokenss with 40 tokers overlapped(40 was chosen after seeing initial have 20 tokens but only seeing one word being repeated)"
      ],
      "metadata": {
        "id": "ir9Zi8rKRUmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks = pdf_loader.load_and_split(text_splitter) #creates a local variable to split the chunks"
      ],
      "metadata": {
        "id": "t4bme7ykm4iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(document_chunks) #checks the size of chunks. These are more than pages, which is expected"
      ],
      "metadata": {
        "id": "J-qG9JW1nGeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks[500].page_content #randomly select one page"
      ],
      "metadata": {
        "id": "ETTUtRbfqSUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks[501].page_content #randomly select the next page"
      ],
      "metadata": {
        "id": "gHE3ZBkHnuH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks[502].page_content #randomly select the page after that"
      ],
      "metadata": {
        "id": "m1HxvQ_3nJKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The data chunking worked as the document chunks are 8,594 and there are about 4,000 pages.\n",
        "\n",
        "I increased the overlap to 40 tokens so it could pull more of a sentence than just a word for the overlap. The three pages selected all have overlap.\n",
        "\n"
      ],
      "metadata": {
        "id": "MhSkQVOmTmor"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvHVejcWz0Bl"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model =SentenceTransformerEmbeddings(model_name='thenlper/gte-large') #this model was chosen because its the same size as the token size we are using"
      ],
      "metadata": {
        "id": "R3CAgoUeRVLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_1 = embedding_model.embed_query(document_chunks[0].page_content) #this sets up checking the embedding\n",
        "embedding_2 = embedding_model.embed_query(document_chunks[1].page_content)"
      ],
      "metadata": {
        "id": "ekls2USGx3Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimension of the embedding vector \",len(embedding_1))\n",
        "len(embedding_1)==len(embedding_2) #this tests the embedding"
      ],
      "metadata": {
        "id": "zOjNxoK0x8RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The data was embedded and it was verified that the dimensions were the same.\n"
      ],
      "metadata": {
        "id": "itp-RtnyU3kR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiKCOv4X0d7B"
      },
      "source": [
        "### Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = 'med_db'# This creates a dir database\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "  os.makedirs(out_dir)"
      ],
      "metadata": {
        "id": "vHHt1MQQRVzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    document_chunks,\n",
        "    embedding_model,\n",
        "    persist_directory=out_dir\n",
        ")#This creates the vector databases from the document chunks and the embedding model. This is to store it in the database"
      ],
      "metadata": {
        "id": "Bpsi80CsyH98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma(persist_directory=out_dir,embedding_function=embedding_model) #This loads the database"
      ],
      "metadata": {
        "id": "D8pjQW6l0zE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.embeddings #This tells me which model is being used internally.  This confirms the right embedding model is being used"
      ],
      "metadata": {
        "id": "nOylNb2y0zm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"Cancer throat radiation\",k=3) #This is a search to see how the embedding is finding the top 3 results."
      ],
      "metadata": {
        "id": "Wtd5BTI69CxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The vector database worked as intended as it did pull up the top responses related to Cancer throat radiation."
      ],
      "metadata": {
        "id": "LUIz-B-kZA_B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEa5sKc41T1z"
      },
      "source": [
        "### Retriever"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={'k': 2}\n",
        ") #variable to conduct retriever activities. This defines the search type to be similarity and that the top 2 similar documents should be pulled"
      ],
      "metadata": {
        "id": "wBlQUGx3RWUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel_docs = retriever.get_relevant_documents(\"what is the prognosis of someone with throat cancer?\") #local variable to test the retriever and getting relevant documents based on a question\n",
        "rel_docs"
      ],
      "metadata": {
        "id": "4p9NBHj2_oy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Conclusion**\n",
        "\n",
        "The response does provide details on the survival rate, but the response is difficult to understand as it it includes details on the source and other irrelevant information (e.g., my email address)."
      ],
      "metadata": {
        "id": "6jf5nCK_ZCOL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8qcwq66B0C",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### System and User Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qna_system_message = \"\"\"\n",
        "\n",
        "You are a medical assistant helping medical professionals synthesize vast volumes of medical data and information to create accurate descriptions, diagnoses, and treatment plans. Your core functions are to assist with synthesizing information based on available records and provide clear and concise information. Your persona is that of a helpful, accurate, and ethical tool. You are not a human clinician.\n",
        "\n",
        "**Primary Directives:**\n",
        "    1.  **Source Reliability:** Use only peer-reviewed medical sources or explicitly provided patient data for generating responses.\n",
        "    2.  **No Hallucinations:** You must prevent the generation of inaccurate or unsupported information. If information is ambiguous, state this and ask for clarification.\n",
        "    3.  **Bias Mitigation:** Be mindful of and explicitly exclude non-clinically relevant demographic descriptors to avoid introducing bias.\n",
        "\n",
        "User questions will begin with the token: ###Question.\n",
        "\n",
        "\n",
        "Remember that the answer to ###Question might not always be directly present in the information provided in the ###Context.\n",
        "the answer can be indirectly derived from the information in ###Context.\n",
        "\n",
        "If the answer is not found in the context, respond \"I don't know\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GF_4399TRW5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qna_user_message_template = \"\"\"\n",
        "Consider the following ###Context and ###Question\n",
        "###Context\n",
        "{context}\n",
        "\n",
        "###Question\n",
        "{question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yCq7ufeWpTPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysis\n",
        "\n",
        "I created a system prompt that outline what the requirements of the AI were and what it's role were. I also did research to identify what potential directives I should be giving this to ensure that it kept hallucinations and biases to a minimum and telling the user \"I don't know if it didn't have an answer\". Then, I created the user message template using a standard context and question format.\n",
        "\n",
        "The goal of the system message was to assist the user with getting informatiom, diagnoses, and treatment plan but not make any decisions."
      ],
      "metadata": {
        "id": "RQFlIOUGUGXl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkIteX4m6mny"
      },
      "source": [
        "### Response Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_response(user_input,k=3,max_tokens=1024,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=k)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    user_message = qna_user_message_template.replace('{context}', context_for_query)\n",
        "    user_message = user_message.replace('{question}', user_input)\n",
        "\n",
        "    prompt = qna_system_message + '\\n' + user_message\n",
        "\n",
        "    # Generate the response\n",
        "    try:\n",
        "        response = llm(\n",
        "                  prompt=prompt,\n",
        "                  max_tokens=max_tokens,\n",
        "                  temperature=temperature,\n",
        "                  top_p=top_p,\n",
        "                  top_k=top_k\n",
        "                  )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response['choices'][0]['text'].strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "5jFvGnOJRXZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering using RAG"
      ],
      "metadata": {
        "id": "ffP1SRYbPQHN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjajBEj06B0E"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the protocols for managing sepsis in a critical care unit? The output should be in an instructional format with bullets. Each bullet should be followed with a verb describing the key action.\"\n",
        "model_response = generate_rag_response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "Nlo9sMpPRbTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The response is clear and provides information that it does not have sufficient context to answer the directly as no context was given. However, it still responds with good information on how to approach managing sepsis.\n",
        "\n"
      ],
      "metadata": {
        "id": "5QSpsf4SU7SL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDw8zXuq6B0F"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''What are the common symptions for appendicitis? Provide if appendicitis can be cured by medication or whether if surgery will be needed. If surgery is needed, describe which surgical procedures should be followed to treat appendicitis.'''\n",
        "model_response = generate_rag_response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "PVReF4G8RbzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The responses is pretty good as the question is outlined on what is needed. The response includes the common symptoms, provides the surgical procedures and whether mediation can be used cure it or how it can be used."
      ],
      "metadata": {
        "id": "-AiLTgvnWli1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TggYyQPL6B0G"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp?\n",
        "\n",
        "What could be the possible causes behind it?'''\n",
        "\n",
        "model_response = generate_rag_response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "0aRbadGtRcX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The response provides a generic answer on the possible causes and effective treatment. As no additional context is provided (e.g., the patient has a certain history or is experiencing certain symptoms), the response provides context that the most effective treatment is going to be based on the underlying cause and severity, which follows the system prompt response."
      ],
      "metadata": {
        "id": "e2NOm5s_aOZ-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TgxdI-_6B0G"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?'''\n",
        "model_response = generate_rag_response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "0vzRX1TcRc29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The response here is clear and provides good details on the treatment. In this response, I see clear details and information than the previous two responses to this questions as it using the RAG to provide a better resposne. It gives more details on there not being one specific treatment as I did not provide any additional context."
      ],
      "metadata": {
        "id": "Kl-W9z22bMBQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlHXYCkm6B0H"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?'''\n",
        "model_response = generate_rag_response(user_input)\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "sarpUibcRdhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The responses provided give good details on the precautions and treatments that need to be followed. Without giving the same inputs as I did in prompt engineering, the resposne is still able to give information on medications needed, treatment options, and things to consider. It does repeat itself as it list antibiotics twice in the response so more the system message may need to clarify that it does not need to repeat information.\n"
      ],
      "metadata": {
        "id": "nYGaKmpzby-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning"
      ],
      "metadata": {
        "id": "K7TYrqycEITB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Background/Choice Selection**\n",
        "\n",
        "For the fine tuning, I selected one question and asked it various times by changing the temperature, the max tokens, the Top P, and the Top K choices.  "
      ],
      "metadata": {
        "id": "ur2TiTnnhtWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp?\n",
        "\n",
        "What could be the possible causes behind it?'''\n",
        "\n",
        "model_response = generate_rag_response(user_input,max_tokens=100) # I limited the number of tokens to 100 to see what difference it would make in the response\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "7UYBR-hcReSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "By limiting the number of tokens, the response is shorter and cut off. However, it does provide the details on possible causes and some potential treatment options. It does not give details on the need to get more information or understanding the cause."
      ],
      "metadata": {
        "id": "bha0FUeTfxR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp?\n",
        "\n",
        "What could be the possible causes behind it?'''\n",
        "\n",
        "model_response = generate_rag_response(user_input,max_tokens=700, temperature=.5)# In this instance, I increased the temperature to .5 to allow more creative answering and had tokens set to 700, which is less than before but more than previous query.\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "SsAMVp7V3y_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "In this instance, I increased the temperature and changed tokens size. The change in temperature caused it to provide additional questions and answer to the differences between scarring and non-scarring forms of alopecia, which was not asked.  It also focuses in on only alopeicia areate as the only cause of hair loss when in previous answers it had given other causes.\n",
        "\n",
        "The temperature being set at .5 may be too high for medical data.\n",
        "\n",
        "The response was complete."
      ],
      "metadata": {
        "id": "Svze6yqlgn6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = '''\n",
        "What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp?\n",
        "\n",
        "What could be the possible causes behind it?'''\n",
        "\n",
        "model_response = generate_rag_response(user_input,max_tokens=700,top_p=0.98, top_k=20) #In this instance, I changed the top_p and top_k variables to allow for more diversity of response without changing the temperature. I also kept tokens at the same\n",
        "print(model_response)"
      ],
      "metadata": {
        "id": "OQZ1fWXK3zaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "For this response, I changed the top_p to .98 and the top_k to 20. The Top P increases the diversity slightly while the Top K reduces it.\n",
        "\n",
        "This response is more focused and directly answers the questions about causes and treatments based on the retrieved context. It doesn't introduce additional questions or delve into differentiating scarring and non-scarring alopecia as the previous response did when temperature was set higher.\n",
        "\n",
        "The response is complete."
      ],
      "metadata": {
        "id": "oovwIcS3hrpi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyQrTipNfuBN"
      },
      "source": [
        "## Output Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbXMSxqa-65E"
      },
      "source": [
        "Let us now use the LLM-as-a-judge method to check the quality of the RAG system on two parameters - retrieval and generation. We illustrate this evaluation based on the answeres generated to the question from the previous section.\n",
        "\n",
        "- We are using the same Mistral model for evaluation, so basically here the llm is rating itself on how well he has performed in the task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groundedness_rater_system_message  = '''You are tasked with rating AI generated answers to questions posed by users.\n",
        "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
        "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the answer.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "The answer should be derived only from the information presented in the context\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the answer as per the metric.\n",
        "2. Give a step-by-step explanation if the answer adheres to the metric considering the question and context as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the answer using the evaluaton criteria and assign a score.'''"
      ],
      "metadata": {
        "id": "IHbfLAxAGdhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevance_rater_system_message = '''You are tasked with rating AI generated answers to questions posed by users.\n",
        "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
        "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the answer.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "Relevance measures how well the answer addresses the main aspects of the question, based on the context.\n",
        "Consider whether all and only the important aspects are contained in the answer when evaluating relevance.\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the context as per the metric.\n",
        "2. Give a step-by-step explanation if the context adheres to the metric considering the question as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the context using the evaluaton criteria and assign a score.'''"
      ],
      "metadata": {
        "id": "159OZZa0Rinv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message_template = '''\"\"\"\n",
        "###Question\n",
        "{question}\n",
        "\n",
        "###Context\n",
        "{context}\n",
        "\n",
        "###Answer\n",
        "{answer}'''"
      ],
      "metadata": {
        "id": "RLqiSn-iRwSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ground_relevance_response(user_input,k=3,max_tokens=1024,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = f\"\"\"[INST]{qna_system_message}\\n\n",
        "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=user_input)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response = llm(\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            echo=False\n",
        "            )\n",
        "\n",
        "    answer =  response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    groundedness_prompt = f\"\"\"[INST]{groundedness_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    relevance_prompt = f\"\"\"[INST]{relevance_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response_1 = llm(\n",
        "            prompt=groundedness_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            echo=False\n",
        "            )\n",
        "\n",
        "    response_2 = llm(\n",
        "            prompt=relevance_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            echo=False\n",
        "            )\n",
        "\n",
        "    return response_1['choices'][0]['text'],response_2['choices'][0]['text']"
      ],
      "metadata": {
        "id": "XIbZybyuRi2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6qxqyJLYA2x"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANzurSjuYA2x"
      },
      "outputs": [],
      "source": [
        "user_input = \"What is the protocol for managing sepsis in a critical care unit\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=600)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A60Q6x3YA2y"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOZQyoLwYA2y"
      },
      "outputs": [],
      "source": [
        "user_input = \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=600)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmYnriTdYA2z"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp898M2iYA2z"
      },
      "outputs": [],
      "source": [
        "user_input = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=600)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-lGsVxYA2z"
      },
      "source": [
        "### Query 4: What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBRTYnFVYA2z"
      },
      "outputs": [],
      "source": [
        "user_input = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=600)\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2WxSxzDYA2z"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKCq09_YYA20"
      },
      "outputs": [],
      "source": [
        "user_input = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=600)\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Conclusion**\n",
        "\n",
        "The evaluation says that the metrics were completely followed, but that the relevance is closer to a 4 for all queries except the first one.\n",
        "\n",
        "The first question is the most specific question out of all of them as it as for a protocal for managing sepsis while the others ask multiple questions and/or do not have enough details to get specific and relevant context (e.g., hiker)."
      ],
      "metadata": {
        "id": "NIZB0lgiqd8n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7QICRU-njdj"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the model and ensure accuracy of information, I would recommend the following:\n",
        "\n",
        "*   Train the model further with internal procedures and processes. Providing more details on any internal process, such as how they deal with sepsis may help give more relevant information.\n",
        "*   Keep Temperature at 0 but consider making changes to the Top K. When the temperature was changed, more irrelevant information was produced. As the evaluation has shown that not all information is relevant, it might be good to reduce the Top K to 20 or so and see if that reduces the amount of not relevant information.\n",
        "* Train the users of the model to provide context when asking a question to make sure the answer is relevant and can be precise.\n",
        "* Review the system message. The system message may need further refinement to ensure that the answers are relevant and it can prompt the user for additional information."
      ],
      "metadata": {
        "id": "_794zCDmV69V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybRlzaIhWaM9"
      },
      "source": [
        "<font size=6 color='blue'>Power Ahead</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3CNz35ia6Bz3",
        "CkRbhMJH6Bz3",
        "CARPKFwm6Bz4",
        "by9EvAnkSpZf",
        "TtZWqj0wFTS1",
        "Uq1lhM4WFTS2",
        "EzzkvIXvFTS4",
        "K8YgK91SFjVY",
        "J6yxICeVFjVc",
        "oflaoOGiFjVd",
        "WUUqY4FbFjVe",
        "5laPFTHrFjVf",
        "g5myZ5dOOefc",
        "9Jg3r_LWOeff",
        "iYpyw4HjOeff",
        "dRp92JQZOeff",
        "AA45zwyUOefg",
        "TYXxiSuBOefg",
        "ffj0ca3eZT4u",
        "f9weTDzMxRRS",
        "7-wNNalNxPKT",
        "LECMxTH-zB-R",
        "BvHVejcWz0Bl",
        "qiKCOv4X0d7B",
        "uEa5sKc41T1z",
        "vw8qcwq66B0C",
        "ffP1SRYbPQHN",
        "JjajBEj06B0E",
        "QDw8zXuq6B0F",
        "TggYyQPL6B0G",
        "1TgxdI-_6B0G",
        "FlHXYCkm6B0H",
        "K7TYrqycEITB"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}